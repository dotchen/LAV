# LAV
![teaser](assets/teaser.svg)
> [**Learning from All Vehicles**](https://dotchen.github.io/LAV/)    
> Dian Chen, Philipp Kr&auml;henb&uuml;hl,        
> _arXiv techical report ([arXiv 2105.00636](https://arxiv.org/abs/2105.00636))_

This repo contains code for paper [Learning from all vehicles](https://arxiv.org/abs/2105.00636).
It performs joint perception, multi-modal prediction and planning, and can serve as a great starter kit for end-to-end autonomous driving research.

## Reference
If you find our repo or paper useful, please cite us as
```bibtex
@inproceedings{chen2022learning,
  title={Learning from all vehicles},
  author={Chen, Dian and Kr{\"a}henb{\"u}hl, Philipp},
  booktitle={CVPR},
  year={2022}
}
```

## Updates
* We have released the inference code! Training code coming soon.

## Getting Started
* To run CARLA and train the models, make sure you are using a machine with **at least** a mid-end GPU.
* Please follow [INSTALL.md](docs/INSTALL.md) to setup the environment.

## Training
- [] TBA

## Evaluation

**Make sure you are launching CARLA with `-vulkan`!**

## Dataset
- [ ] TBA

## License
This repo is released under the GPL License (please refer to the LICENSE file for details).
